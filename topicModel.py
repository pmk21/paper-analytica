import pickle
import numpy as np
from sklearn.decomposition import NMF, LatentDirichletAllocation
from preprocess import preprocess_text


def display_topics(model, feature_names, no_top_words):
    for topic_idx, topic in enumerate(model.components_):
        print("Topic %d:" % (topic_idx))
        print(" ".join([feature_names[i]
                        for i in topic.argsort()[:-no_top_words - 1:-1]]))
        # print("content:",[i for i in topic.argsort()[:-no_top_words - 1:-1]])

def possibleTopics(tfidf_model, vectSum):
    """ 
        Takes the vectorized summary data, which is generated by the tfidf model
        and finds the possible topics of the papers
        using Topic Modeling and Non-negative Matrix Factorization,
        the input query is classified into one of the topics.
        
        Parameters
        -----------------
        query : user's query to the recommendation engine
        tfidf_model : sklearn.feature_extraction.text.TfidfVectorizer
                The model which is used to extract the tfidf vectors from a given processed corpus
        vectSum: scipy.sparse.csr.csr_matrix
                The matrix with tfidf vectors of all the papers

    """
    no_top_words = 10
    no_components = 5
    tf_feature_names = tfidf_model.get_feature_names()
    trial = ["Manifold", "analysis", "and", "dimensionality" ,"reduction", "image", "processing", "convolutional", "neural", "networks"]
    processedQuery = np.array(list(map(preprocess_text, trial)))
    vectQuery = tfidf_model.transform(processedQuery)
    processedfeatures = np.array(list(map(preprocess_text, tf_feature_names)))

    nmf_model = NMF(n_components=no_components, random_state=1,
              alpha=.1, l1_ratio=.5, init='nndsvd').fit(vectSum)
    display_topics(nmf_model, processedfeatures, no_top_words)
    topic_probability_scores = nmf_model.transform(vectQuery)
    #gives the probability of each topic for the query in a matrix of (top_words * topics) form
    print(topic_probability_scores)



if __name__ == "__main__":
    data_dir = "./data/"

    with open(data_dir + 'vectorizer.pk', 'rb') as pickle_in:
        vectorizer = pickle.load(pickle_in)

    with open(data_dir + "tfidf-vectors-200.pk", "rb") as fp:
        vectSum = pickle.load(fp)

    possibleTopics(vectorizer, vectSum)

